# Portfolio Application - Local K3s Deployment

Complete local Kubernetes (k3s) deployment for the Portfolio application with PostgreSQL read replica and load-balanced image service.

## ğŸš€ Quick Start
```bash
# 1. Build and import images to k3s (no registry needed)
./build-and-import-k3s.sh

# 2. Deploy everything
./deploy-k3s-local.sh

# 3. Create admin user
kubectl exec -n portfolio deployment/backend -- \
  python -m scripts.admin.create_admin

# 4. Access application
kubectl get svc nginx -n portfolio
# Visit http://<NODE-IP>:<NODEPORT>
```

## ğŸ“¦ Local Image Workflow

This deployment uses **local images** imported directly into k3s - no external registry required.

### Images Used
- **Custom (built locally):**
  - `portfolio-postgres:latest` - Custom Postgres with SSL & pg_cron
  - `portfolio-backend:latest` - FastAPI application
  - `portfolio-image-service:latest` - Image processing service
  - `portfolio-nginx:latest` - Web server + frontend
  
- **Public (pulled automatically):**
  - `redis:7-alpine`
  - `minio/minio:latest`

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ backend/                    # FastAPI backend application
â”œâ”€â”€ image-service/              # Image processing microservice
â”œâ”€â”€ nginx/                      # Web server and frontend
â”œâ”€â”€ postgres/                   # Custom PostgreSQL setup
â”œâ”€â”€ k8s/                        # Kubernetes manifests
â”‚   â”œâ”€â”€ 00-namespace.yaml
â”‚   â”œâ”€â”€ 01-configmap.yaml
â”‚   â”œâ”€â”€ 02-secrets.yaml
â”‚   â”œâ”€â”€ 03-pvcs.yaml
â”‚   â”œâ”€â”€ 04-postgres-primary.yaml
â”‚   â”œâ”€â”€ 05-postgres-replica.yaml
â”‚   â”œâ”€â”€ 06-redis.yaml
â”‚   â”œâ”€â”€ 07-minio.yaml
â”‚   â”œâ”€â”€ 08-image-service.yaml
â”‚   â”œâ”€â”€ 09-backend.yaml
â”‚   â””â”€â”€ 10-nginx.yaml
â”œâ”€â”€ k8s scripts/                # Deployment automation
â”‚   â”œâ”€â”€ ARCHITECTURE.md         # System architecture diagrams
â”‚   â”œâ”€â”€ build-and-import-k3s.sh # Build & import images to k3s
â”‚   â”œâ”€â”€ cleanup.sh              # Remove all resources
â”‚   â”œâ”€â”€ deploy-k3s-local.sh     # Automated deployment
â”‚   â””â”€â”€ DEPLOYMENT-GUIDE.md     # Step-by-step guide
â””â”€â”€ README.md                   # This file
```

**Note:** `.credentials/` directory will be auto-generated by the deployment script and is git-ignored.

## ğŸ—ï¸ Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚Load Balancerâ”‚
                    â”‚   (nginx)   â”‚
                    â”‚  NodePort   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â”‚                  â”‚
        â–¼                  â–¼                  â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Backend â”‚      â”‚Image Serviceâ”‚    â”‚  Static  â”‚
   â”‚  (2x)  â”‚      â”‚    (2x)     â”‚    â”‚  Files   â”‚
   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚
       â”‚                  â”‚
       â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL  â”‚   â”‚  MinIO   â”‚
â”‚   Primary    â”‚   â”‚   (1x)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ replication
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL  â”‚   â”‚  Redis   â”‚
â”‚   Replica    â”‚   â”‚   (1x)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  (reads only)
```

### Components

- **Nginx (1x)**: Reverse proxy, static file serving, load balancing via NodePort
- **Backend (2x)**: FastAPI application, API endpoints
- **Image Service (2x)**: Image processing, NSFW detection, MinIO storage
- **PostgreSQL Primary (1x)**: Write database, replication master
- **PostgreSQL Replica (1x)**: Read-only database replica
- **Redis (1x)**: Cache layer, rate limiting
- **MinIO (1x)**: S3-compatible object storage

### Local Resource Requirements

- **Minimum**: 2 CPU cores, 4GB RAM, 30GB disk
- **Recommended**: 4 CPU cores, 8GB RAM, 50GB disk

## ğŸ”§ Configuration

### Environment Variables

Key configurations are set in:
- `k8s/01-configmap.yaml` - Non-sensitive config
- `k8s/02-secrets.yaml` - Sensitive credentials (base64 encoded)

**Local Development Defaults:**
- Database: `postgresql://postgres@postgres-primary:5432/portfolio`
- MinIO: `http://minio:9000` (accessible via NodePort)
- Redis: `redis://redis:6379`
- Frontend: `http://localhost:<NODEPORT>`

## ğŸ”„ Common Operations

### Scaling Services

```bash
# Scale backend replicas
kubectl scale deployment backend -n portfolio --replicas=3

# Scale image service
kubectl scale deployment image-service -n portfolio --replicas=4

# Verify scaling
kubectl get deployments -n portfolio
```

### Monitoring

```bash
# View all pods
kubectl get pods -n portfolio -o wide

# Watch pod status in real-time
kubectl get pods -n portfolio -w

# Check pod logs
kubectl logs -n portfolio deployment/backend -f
kubectl logs -n portfolio deployment/image-service -f

# Resource usage (requires metrics-server)
kubectl top pods -n portfolio
kubectl top nodes

# Check recent events
kubectl get events -n portfolio --sort-by='.lastTimestamp'
```

### Database Operations

```bash
# Connect to primary database (for writes)
kubectl exec -it -n portfolio postgres-primary-0 -- \
  psql -U postgres -d portfolio

# Connect to replica database (for reads)
kubectl exec -it -n portfolio postgres-replica-0 -- \
  psql -U postgres -d portfolio

# Check replication status
kubectl exec -n portfolio postgres-primary-0 -- \
  psql -U postgres -d portfolio -c \
  "SELECT application_name, state, sync_state, replay_lag 
   FROM pg_stat_replication;"

# Verify replica is in recovery mode
kubectl exec -n portfolio postgres-replica-0 -- \
  psql -U postgres -d postgres -c \
  "SELECT pg_is_in_recovery();"
```

### Updating Application

```bash
# Rebuild and import new image
cd backend
docker build -t portfolio-backend:latest .
sudo k3s ctr images import portfolio-backend.tar

# Restart deployment to use new image
kubectl rollout restart deployment/backend -n portfolio

# Monitor rollout
kubectl rollout status deployment/backend -n portfolio

# Check rollout history
kubectl rollout history deployment/backend -n portfolio

# Rollback if needed
kubectl rollout undo deployment/backend -n portfolio
```

### Backup & Restore

```bash
# Backup database
kubectl exec -n portfolio postgres-primary-0 -- \
  pg_dump -U postgres portfolio | gzip > backup-$(date +%Y%m%d).sql.gz

# Restore database
gunzip -c backup-20250201.sql.gz | \
  kubectl exec -i -n portfolio postgres-primary-0 -- \
  psql -U postgres portfolio

# Backup MinIO data
kubectl exec -n portfolio deployment/minio -- \
  tar czf - /data | cat > minio-backup-$(date +%Y%m%d).tar.gz
```

### Accessing Services Locally

```bash
# Get all service endpoints
kubectl get svc -n portfolio

# Access nginx (frontend)
kubectl get svc nginx -n portfolio
# Visit http://<NODE-IP>:<NODEPORT>

# Port forward for direct access
kubectl port-forward -n portfolio svc/nginx 8080:80
# Visit http://localhost:8080

# Access MinIO console
kubectl port-forward -n portfolio svc/minio 9001:9001
# Visit http://localhost:9001

# Access backend API docs
kubectl port-forward -n portfolio svc/backend 8000:8000
# Visit http://localhost:8000/docs
```

## ğŸ› Troubleshooting

### Pods Not Starting

```bash
# Check pod status and events
kubectl describe pod -n portfolio <pod-name>

# View detailed logs
kubectl logs -n portfolio <pod-name> --previous
kubectl logs -n portfolio <pod-name> --all-containers

# Check resource constraints
kubectl top pods -n portfolio
kubectl describe nodes
```

### Image Import Issues

```bash
# List imported images in k3s
sudo k3s ctr images list | grep portfolio

# Manually import image
docker save portfolio-backend:latest -o /tmp/backend.tar
sudo k3s ctr images import /tmp/backend.tar

# Force pod to use latest image
kubectl delete pod -n portfolio -l app=backend
```

### Database Connection Issues

```bash
# Test connectivity from backend pod
kubectl exec -n portfolio deployment/backend -- \
  pg_isready -h postgres-primary -U postgres

# Check PostgreSQL service DNS
kubectl exec -n portfolio deployment/backend -- \
  nslookup postgres-primary

# View PostgreSQL logs
kubectl logs -n portfolio postgres-primary-0 -f
kubectl logs -n portfolio postgres-replica-0 -f
```

### Replica Not Syncing

```bash
# Check replication slot status
kubectl exec -n portfolio postgres-primary-0 -- \
  psql -U postgres -d portfolio -c \
  "SELECT slot_name, active, restart_lsn FROM pg_replication_slots;"

# Check replication lag
kubectl exec -n portfolio postgres-primary-0 -- \
  psql -U postgres -d portfolio -c \
  "SELECT EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp())) 
   AS lag_seconds FROM pg_stat_replication;"

# Reinitialize replica (if corrupted)
kubectl delete pod -n portfolio postgres-replica-0
# StatefulSet will automatically recreate and re-sync
```

### MinIO/Image Service Issues

```bash
# Test MinIO connectivity
kubectl exec -n portfolio deployment/image-service -- \
  curl -v http://minio:9000/minio/health/live

# Check MinIO bucket exists
kubectl exec -n portfolio deployment/minio -- \
  mc ls local/portfolio-images

# Check NSFW model loading
kubectl logs -n portfolio deployment/image-service | grep -i nsfw
```

### Network Issues

```bash
# Test pod-to-pod connectivity
kubectl run -n portfolio test-pod --rm -it --image=nicolaka/netshoot -- bash
# Inside pod:
curl http://backend:8000/health
curl http://postgres-primary:5432
curl http://redis:6379

# Check service endpoints
kubectl get endpoints -n portfolio

# Verify DNS resolution
kubectl exec -n portfolio deployment/backend -- nslookup postgres-primary
```

## ğŸ“Š Performance Tuning

### PostgreSQL Optimization

```yaml
# Edit postgres configmap to tune:
shared_buffers: 256MB           # 25% of available RAM
effective_cache_size: 768MB     # 75% of available RAM
work_mem: 16MB                  # Per operation
maintenance_work_mem: 64MB      # For VACUUM, INDEX
max_connections: 100
```

### Backend Tuning

```yaml
# Increase workers in backend deployment:
command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--workers", "4"]

# Tune connection pool:
env:
  - name: DB_POOL_MIN_SIZE
    value: "5"
  - name: DB_POOL_MAX_SIZE
    value: "20"
```

### Resource Limits

```yaml
# Adjust in deployment manifests:
resources:
  requests:
    memory: "512Mi"
    cpu: "250m"
  limits:
    memory: "1Gi"
    cpu: "1000m"
```

## ğŸ”’ Security Considerations

### âš ï¸ CRITICAL: Production Security Checklist

**This is a LOCAL DEVELOPMENT setup. Before deploying to production:**

1. **Remove Admin Bypass Logic**
   ```
   Remove CSRF bypass from backend/app/auth/csrf.py (lines 75-130)
   This allows admin API key to bypass CSRF protection - NOT FOR PRODUCTION!
   ```

2. **Generate Strong Secrets**
   ```bash
   # Generate secure passwords (32 bytes = 256 bits)
   openssl rand -base64 32
   
   # Update these in k8s/02-secrets.yaml:
   - POSTGRES_PASSWORD
   - SECRET_KEY
   - ADMIN_API_KEY
   - MINIO_ROOT_PASSWORD
   ```

3. **Restrict Network Access**
   ```bash
   # Use NetworkPolicies to isolate pods
   # Only backend should access postgres
   # Only image-service should access minio
   ```

4. **Enable HTTPS**
   ```bash
   # For production, use cert-manager + Let's Encrypt
   kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.0/cert-manager.yaml
   ```

5. **Update Production URLs**
   ```yaml
   # In k8s/01-configmap.yaml:
   API_BASE_URL: "https://yourdomain.com"
   ALLOWED_ORIGINS: "https://yourdomain.com"
   ```

6. **Configure Real Email Service**
   ```yaml
   # Add real Resend API key in k8s/02-secrets.yaml
   RESEND_API_KEY: <your-real-api-key>
   ```

### Current Local Security Setup

- PostgreSQL uses SSL/TLS with self-signed certificates
- All services communicate via internal ClusterIP (not exposed)
- Only nginx is exposed via NodePort for local access
- Passwords are base64 encoded (not encrypted at rest)

## ğŸ§¹ Cleanup

```bash
# Complete cleanup (removes all data)
./cleanup.sh

# Or manually:
kubectl delete namespace portfolio

# Verify cleanup
kubectl get all -n portfolio
sudo k3s ctr images list | grep portfolio
```

## ğŸ“š Additional Documentation

- **[DEPLOYMENT-GUIDE.md](k8s%20scripts/DEPLOYMENT-GUIDE.md)** - Step-by-step deployment instructions
- **[ARCHITECTURE.md](k8s%20scripts/ARCHITECTURE.md)** - Detailed architecture and scaling strategies
- **Backend API Docs**: `http://localhost:<NODEPORT>/docs` (after port-forward)

## ğŸš€ Development Workflow

```bash
# 1. Make changes to code
vim backend/app/main.py

# 2. Rebuild image
cd backend
docker build -t portfolio-backend:latest .

# 3. Save and import to k3s
docker save portfolio-backend:latest -o /tmp/backend.tar
sudo k3s ctr images import /tmp/backend.tar

# 4. Restart deployment
kubectl rollout restart deployment/backend -n portfolio

# 5. Watch rollout
kubectl rollout status deployment/backend -n portfolio

# 6. Test changes
kubectl port-forward -n portfolio svc/backend 8000:8000
curl http://localhost:8000/health
```

## ğŸ¯ Next Steps

1. âœ… Deploy locally using quick start guide
2. âœ… Verify all services are running
3. âœ… Create admin user
4. âœ… Test frontend and API
5. âœ… Try scaling services
6. âœ… Practice backup/restore
7. âš ï¸ Review security checklist before production
8. âš ï¸ Set up monitoring (Prometheus/Grafana)
9. âš ï¸ Configure ingress with TLS
10. âš ï¸ Enable automated backups

## â­ Features

âœ… PostgreSQL Primary + Replica for read scaling  
âœ… 2x Image Service replicas with automatic load balancing  
âœ… 2x Backend replicas with rolling updates  
âœ… Persistent storage for all stateful services  
âœ… SSL/TLS for PostgreSQL connections  
âœ… Health checks and auto-restart  
âœ… Resource limits and requests  
âœ… NSFW content detection  
âœ… Redis caching layer  
âœ… Automated migrations on deployment  
âœ… Local k3s deployment (no external registry needed)  
âœ… StatefulSets for databases  
âœ… ConfigMaps and Secrets management  

## ğŸ¤ Support

For issues or questions:

1. **Check logs**: `kubectl logs -n portfolio <pod-name> -f`
2. **Review events**: `kubectl get events -n portfolio --sort-by='.lastTimestamp'`
3. **Check resources**: `kubectl top pods -n portfolio`
4. **Verify networking**: `kubectl get svc,endpoints -n portfolio`
5. **Describe resources**: `kubectl describe pod -n portfolio <pod-name>`

## ğŸ“ License

[Your License Here]

---

**Local K3s Deployment** | Built for development and testing | Not for production without security hardening